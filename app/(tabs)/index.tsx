import React, { useState, useRef, useEffect } from 'react';
import { StyleSheet, View, TouchableOpacity, Alert, Platform } from 'react-native';
import { Audio } from 'expo-av';

import { ThemedText } from '@/components/ThemedText';
import { ThemedView } from '@/components/ThemedView';

// Web Speech APIã®ã‚¿ã‚¤ãƒ—å®šç¾©ï¼ˆWebã®ã¿ï¼‰
declare global {
  interface Window {
    webkitSpeechRecognition: any;
    SpeechRecognition: any;
  }
}

export default function HomeScreen() {
  const [isRecording, setIsRecording] = useState(false);
  const [recordingDuration, setRecordingDuration] = useState(0);
  const [recording, setRecording] = useState<Audio.Recording | null>(null);
  const [recordingUri, setRecordingUri] = useState<string | null>(null);
  const [savedRecordings, setSavedRecordings] = useState<string[]>([]);
  const [transcription, setTranscription] = useState('');
  const [rawAlternatives, setRawAlternatives] = useState<string[]>([]);
  const [isListening, setIsListening] = useState(false);
  const [speechSupported, setSpeechSupported] = useState(false);
  const [whisperResult, setWhisperResult] = useState<{raw: string, katakana: string} | null>(null);
  const [isProcessingWhisper, setIsProcessingWhisper] = useState(false);
  const timerRef = useRef<NodeJS.Timeout | null>(null);
  const recognitionRef = useRef<any>(null);

  useEffect(() => {
    if (Platform.OS === 'web') {
      // Webãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ç”¨ã®ç¢ºèª
      const supported = typeof window !== 'undefined' && 
        ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window);
      setSpeechSupported(supported);
      
      if (supported) {
        setupWebSpeechRecognition();
      }
    } else {
      // iOS/Androidã§ã¯ç¾åœ¨ã®Expo Goã§ã¯åˆ¶é™ãŒã‚ã‚‹ãŸã‚ã€Development BuildãŒå¿…è¦
      setSpeechSupported(false);
      console.log('iOS/Android speech recognition requires Development Build');
    }
  }, []);

  const selectRawCandidate = (alternatives: string[]): string => {
    if (alternatives.length === 0) return '';
    if (alternatives.length === 1) return alternatives[0];

    // ã‚ˆã‚Šã€Œç”Ÿã€ã®ç™ºéŸ³ã«è¿‘ã„å€™è£œã‚’é¸æŠã™ã‚‹ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯
    const scored = alternatives.map((alt, index) => {
      let score = 0;
      
      // å¾Œã®å€™è£œã»ã©ä¿¡é ¼åº¦ãŒä½ã„ï¼ˆï¼è£œæ­£ãŒå°‘ãªã„å¯èƒ½æ€§ï¼‰
      score += (alternatives.length - index) * 10;
      
      // çŸ­ã„å˜èªã¯ç™ºéŸ³ãŒä¸å®Œå…¨ãªå¯èƒ½æ€§
      if (alt.length < alternatives[0].length) score += 20;
      
      // ä¸€èˆ¬çš„ã§ãªã„å˜èªãƒ»éŸ³ã®çµ„ã¿åˆã‚ã›ã‚’å„ªå…ˆ
      const commonWords = ['hello', 'thank', 'you', 'water', 'good', 'morning'];
      const isCommon = commonWords.some(word => 
        alt.toLowerCase().includes(word.toLowerCase())
      );
      if (!isCommon) score += 15;
      
      // ã‚ˆã‚Šå¤šãã®å­éŸ³ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãŒã‚ã‚‹ï¼ˆç™ºéŸ³ã®ç‰¹å¾´ã‚’ä¿æŒï¼‰
      const consonantClusters = alt.match(/[bcdfghjklmnpqrstvwxyz]{2,}/gi) || [];
      score += consonantClusters.length * 5;
      
      return { alt, score, index };
    });
    
    // æœ€é«˜ã‚¹ã‚³ã‚¢ã®å€™è£œã‚’é¸æŠ
    scored.sort((a, b) => b.score - a.score);
    console.log('Candidate scores:', scored);
    
    return scored[0].alt;
  };

  const setupWebSpeechRecognition = () => {
    const SpeechRecognitionAPI = window.webkitSpeechRecognition || window.SpeechRecognition;
    if (!SpeechRecognitionAPI) return;

    const recognition = new SpeechRecognitionAPI();
    
    // ç”Ÿã®ç™ºéŸ³ã«ã‚ˆã‚Šè¿‘ã¥ã‘ã‚‹è¨­å®š
    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = 'en'; // ã‚ˆã‚Šæ±ç”¨çš„ãªè¨­å®š
    recognition.maxAlternatives = 5; // è¤‡æ•°ã®å€™è£œã‚’å–å¾—
    recognition.serviceURI = ''; // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ç”¨

    recognition.onstart = () => {
      setIsListening(true);
      console.log('Web speech recognition started');
    };

    recognition.onend = () => {
      setIsListening(false);
      console.log('Web speech recognition ended');
    };

    recognition.onresult = (event: any) => {
      if (event.results.length > 0) {
        const lastResult = event.results[event.results.length - 1];
        
        // å…¨ã¦ã®ä»£æ›¿å€™è£œã‚’å–å¾—
        const alternatives: string[] = [];
        for (let i = 0; i < lastResult.length && i < 5; i++) {
          if (lastResult[i]) {
            alternatives.push(lastResult[i].transcript);
          }
        }
        
        console.log('All alternatives:', alternatives);
        setRawAlternatives(alternatives);
        
        // ã‚ˆã‚Šã€Œç”Ÿã€ã«è¿‘ã„å€™è£œã‚’é¸æŠã™ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
        const selectedTranscript = selectRawCandidate(alternatives);
        console.log('Selected raw transcript:', selectedTranscript);
        
        const katakanaResult = 'ï¼Ÿï¼Ÿï¼Ÿï¼ˆWeb Speech APIçµæœã¯è¡¨ç¤ºã•ã‚Œã¾ã›ã‚“ï¼‰ï¼Ÿï¼Ÿï¼Ÿ';
        setTranscription(katakanaResult);
      }
    };

    recognition.onerror = (event: any) => {
      console.error('Web speech recognition error:', event.error);
      setIsListening(false);
    };

    recognitionRef.current = recognition;
  };

  const startRecording = async () => {
    try {
      console.log('Requesting permissions..');
      await Audio.requestPermissionsAsync();

      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
      });

      console.log('Starting recording..');
      const { recording } = await Audio.Recording.createAsync(
        Audio.RecordingOptionsPresets.HIGH_QUALITY
      );
      setRecording(recording);
      setIsRecording(true);
      setTranscription('');
      setRawAlternatives([]);
      setRecordingUri(null);

      // éŸ³å£°èªè­˜é–‹å§‹ï¼ˆWebã®ã¿ï¼‰
      if (speechSupported && Platform.OS === 'web' && recognitionRef.current) {
        try {
          recognitionRef.current.start();
        } catch (error) {
          console.error('Error starting web recognition:', error);
        }
      }

      console.log('Recording started');

      timerRef.current = setInterval(() => {
        setRecordingDuration(prev => {
          if (prev >= 30) {
            stopRecording();
            return 30;
          }
          return prev + 1;
        });
      }, 1000);
    } catch (err) {
      console.error('Failed to start recording', err);
      Alert.alert('éŒ²éŸ³ã‚¨ãƒ©ãƒ¼', 'éŒ²éŸ³ã‚’é–‹å§‹ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚æ¨©é™ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚');
    }
  };

  const stopRecording = async () => {
    console.log('Stopping recording..');
    
    if (timerRef.current) {
      clearInterval(timerRef.current);
      timerRef.current = null;
    }

    // éŸ³å£°èªè­˜åœæ­¢ï¼ˆWebã®ã¿ï¼‰
    if (speechSupported && Platform.OS === 'web' && recognitionRef.current) {
      try {
        recognitionRef.current.stop();
      } catch (error) {
        console.error('Error stopping web recognition:', error);
      }
    }

    if (!recording) {
      return;
    }

    try {
      await recording.stopAndUnloadAsync();
      const uri = recording.getURI();
      setRecordingUri(uri);
      console.log('Recording stopped and stored at', uri);
      
      // éŸ³å£°èªè­˜ãŒåˆ©ç”¨ã§ããªã„ã€ã¾ãŸã¯ä½•ã‚‚èªè­˜ã•ã‚Œãªã‹ã£ãŸå ´åˆ
      if (!speechSupported) {
        if (Platform.OS === 'web') {
          setTranscription('ï¼Ÿï¼Ÿï¼Ÿï¼ˆãƒ–ãƒ©ã‚¦ã‚¶ãŒéŸ³å£°èªè­˜ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã›ã‚“ï¼‰ï¼Ÿï¼Ÿï¼Ÿ');
        } else {
          setTranscription('ï¼Ÿï¼Ÿï¼Ÿï¼ˆiOS/Androidã§ã¯ Development Build ãŒå¿…è¦ã§ã™ï¼‰ï¼Ÿï¼Ÿï¼Ÿ');
        }
      } else if (!transcription) {
        setTranscription('ï¼Ÿï¼Ÿï¼Ÿï¼ˆéŸ³å£°ãŒèªè­˜ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼‰ï¼Ÿï¼Ÿï¼Ÿ');
      }
    } catch (error) {
      console.error('Error stopping recording:', error);
    }

    setRecording(null);
    setIsRecording(false);
    setRecordingDuration(0);
  };

  const playRecording = async () => {
    if (!recordingUri) {
      Alert.alert('ã‚¨ãƒ©ãƒ¼', 'å†ç”Ÿã™ã‚‹éŒ²éŸ³ãŒã‚ã‚Šã¾ã›ã‚“');
      return;
    }

    try {
      const { sound } = await Audio.Sound.createAsync({ uri: recordingUri });
      await sound.playAsync();
    } catch (error) {
      console.error('Error playing recording:', error);
      Alert.alert('ã‚¨ãƒ©ãƒ¼', 'éŒ²éŸ³ã®å†ç”Ÿã«å¤±æ•—ã—ã¾ã—ãŸ');
    }
  };


  const processWithWhisper = async () => {
    console.log('è§£æãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚Œã¾ã—ãŸ');
    console.log('recordingUri:', recordingUri);
    
    if (!recordingUri) {
      console.log('éŒ²éŸ³URIãŒã‚ã‚Šã¾ã›ã‚“');
      Alert.alert('ã‚¨ãƒ©ãƒ¼', 'è§£æã™ã‚‹éŒ²éŸ³ãŒã‚ã‚Šã¾ã›ã‚“');
      return;
    }

    setIsProcessingWhisper(true);
    setWhisperResult(null);
    
    try {
      // Hugging Face Spaces APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
      const API_URL = 'https://naonta44-whisper-pronunciation-api.hf.space/api/predict';
      
      // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
      const response = await fetch(recordingUri);
      const audioBlob = await response.blob();
      
      // FormDataã‚’ä½œæˆ
      const formData = new FormData();
      formData.append('data', JSON.stringify([null, audioBlob]));
      
      console.log('Hugging Face Spaces APIã«é€ä¿¡ä¸­...');
      
      // APIãƒªã‚¯ã‚¨ã‚¹ãƒˆ
      const apiResponse = await fetch(API_URL, {
        method: 'POST',
        body: formData,
        headers: {
          'Accept': 'application/json',
        },
      });
      
      if (!apiResponse.ok) {
        throw new Error(`API Error: ${apiResponse.status} ${apiResponse.statusText}`);
      }
      
      const result = await apiResponse.json();
      console.log('HF Spaces APIçµæœ:', result);
      
      // Gradio APIã®çµæœã‚’ãƒ‘ãƒ¼ã‚¹
      if (result && result.data && result.data[0]) {
        const resultText = result.data[0];
        
        // çµæœã‹ã‚‰è‹±èªè¡¨è¨˜ã¨ã‚«ã‚¿ã‚«ãƒŠè¡¨è¨˜ã‚’æŠ½å‡º
        const englishMatch = resultText.match(/\*\*è‹±èªè¡¨è¨˜:\*\* (.+)/);
        const katakanaMatch = resultText.match(/\*\*ã‚«ã‚¿ã‚«ãƒŠè¡¨è¨˜:\*\* (.+)/);
        
        const englishText = englishMatch ? englishMatch[1].trim() : 'èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸ';
        const katakanaText = katakanaMatch ? katakanaMatch[1].trim() : 'ï¼Ÿï¼Ÿï¼Ÿ';
        
        setWhisperResult({
          raw: englishText,
          katakana: katakanaText
        });
      } else {
        throw new Error('APIã‹ã‚‰äºˆæœŸã—ãªã„çµæœãŒè¿”ã•ã‚Œã¾ã—ãŸ');
      }
      
    } catch (error) {
      console.error('Hugging Face Spaces API ã‚¨ãƒ©ãƒ¼:', error);
      
      // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ­ãƒ¼ã‚«ãƒ«ã®ãƒ¢ãƒƒã‚¯çµæœ
      console.log('ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ¢ãƒƒã‚¯çµæœã‚’ä½¿ç”¨');
      const mockResults = [
        { raw: "hello world", katakana: "ãƒãƒ­ãƒ¼ ãƒ¯ãƒ¼ãƒ«ãƒ‰" },
        { raw: "thank you very much", katakana: "ã‚µãƒ³ã‚¯ ãƒ¦ãƒ¼ ãƒ™ãƒªãƒ¼ ãƒãƒ" },
        { raw: "good morning", katakana: "ã‚°ãƒƒãƒ‰ ãƒ¢ãƒ¼ãƒ‹ãƒ³ã‚°" }
      ];
      
      const randomResult = mockResults[Math.floor(Math.random() * mockResults.length)];
      setWhisperResult({
        raw: randomResult.raw,
        katakana: randomResult.katakana
      });
      
      Alert.alert('æ³¨æ„', 'APIæ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ‡ãƒ¢çµæœã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚');
    } finally {
      setIsProcessingWhisper(false);
    }
  };

  const createDevelopmentBuild = () => {
    Alert.alert(
      'Development Buildä½œæˆæ–¹æ³•', 
      'iOSã§éŸ³å£°èªè­˜ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ Development Build ãŒå¿…è¦ã§ã™ã€‚\n\næ‰‹é †:\n1. npx expo install expo-dev-client\n2. npx expo run:ios\n3. å®Ÿæ©Ÿã¾ãŸã¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ã§å®Ÿè¡Œ',
      [{ text: 'OK' }]
    );
  };

  return (
    <ThemedView style={styles.container}>
      <ThemedText type="title" style={styles.title}>
        è‹±èªç™ºéŸ³æ–‡å­—èµ·ã“ã—
      </ThemedText>
      
      
      <View style={styles.recordingContainer}>
        <TouchableOpacity
          style={[
            styles.recordButton,
            { backgroundColor: isRecording ? '#ff4444' : '#4CAF50' }
          ]}
          onPress={isRecording ? stopRecording : startRecording}
        >
          <ThemedText style={styles.recordButtonText}>
            {isRecording ? 'åœæ­¢' : 'éŒ²éŸ³é–‹å§‹'}
          </ThemedText>
        </TouchableOpacity>
        
        {isRecording && (
          <View style={styles.statusContainer}>
            <ThemedText style={styles.timer}>
              {recordingDuration}ç§’ / 30ç§’ ğŸ¤
            </ThemedText>
            {speechSupported && isListening && (
              <ThemedText style={styles.listeningStatus}>
                éŸ³å£°èªè­˜ä¸­... ğŸ”Š
              </ThemedText>
            )}
          </View>
        )}
      </View>



      {recordingUri && (
        <View style={styles.actionButtonsContainer}>
          <TouchableOpacity style={styles.playButton} onPress={playRecording}>
            <ThemedText style={styles.playButtonText}>
              éŒ²éŸ³ã‚’å†ç”Ÿ ğŸ”Š
            </ThemedText>
          </TouchableOpacity>
          <TouchableOpacity 
            style={[styles.whisperButton, isProcessingWhisper && styles.processingButton]} 
            onPress={processWithWhisper}
            disabled={isProcessingWhisper}
          >
            <ThemedText style={styles.whisperButtonText}>
              {isProcessingWhisper ? 'è§£æä¸­... â³' : 'è§£æ ğŸ¯'}
            </ThemedText>
          </TouchableOpacity>
        </View>
      )}

      {whisperResult && (
        <View style={styles.comparisonContainer}>
          <ThemedText style={styles.comparisonTitle}>
            ğŸ¤ è§£æçµæœ
          </ThemedText>
          <View style={styles.resultItem}>
            <ThemedText style={styles.resultLabel}>ã‚«ã‚¿ã‚«ãƒŠè¡¨è¨˜:</ThemedText>
            <ThemedText style={styles.resultText}>
              {whisperResult.katakana}
            </ThemedText>
          </View>
          <View style={styles.resultItem}>
            <ThemedText style={styles.resultLabel}>è‹±èªè¡¨è¨˜:</ThemedText>
            <ThemedText style={styles.resultText}>
              "{whisperResult.raw}"
            </ThemedText>
          </View>
          <TouchableOpacity 
            style={styles.clearComparisonButton}
            onPress={() => setWhisperResult(null)}
          >
            <ThemedText style={styles.clearComparisonButtonText}>çµæœã‚’ã‚¯ãƒªã‚¢</ThemedText>
          </TouchableOpacity>
        </View>
      )}

      <View style={styles.supportInfo}>
        <ThemedText style={styles.supportText}>
          éŸ³å£°èªè­˜: {speechSupported ? 'âœ… åˆ©ç”¨å¯èƒ½' : 'âŒ åˆ©ç”¨ä¸å¯'}
        </ThemedText>
        <ThemedText style={styles.supportText}>
          ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ : {Platform.OS}
        </ThemedText>
        {!speechSupported && Platform.OS !== 'web' && (
          <TouchableOpacity style={styles.helpButton} onPress={createDevelopmentBuild}>
            <ThemedText style={styles.helpButtonText}>
              iOSå¯¾å¿œæ–¹æ³•ã‚’è¦‹ã‚‹
            </ThemedText>
          </TouchableOpacity>
        )}
      </View>

      <ThemedText style={styles.instruction}>
        éŒ²éŸ³ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦è‹±èªã‚’è©±ã—ã¦ãã ã•ã„ã€‚
        {speechSupported ? 
          'å®Ÿéš›ã®ç™ºéŸ³ãŒãã®ã¾ã¾ã‚«ã‚¿ã‚«ãƒŠã§è¡¨ç¤ºã•ã‚Œã¾ã™ï¼ˆè£œæ­£ãªã—ï¼‰ã€‚' :
          Platform.OS === 'web' ? 
            'ãƒ–ãƒ©ã‚¦ã‚¶ãŒéŸ³å£°èªè­˜ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã›ã‚“ã€‚' :
            'iOSã§ã®éŸ³å£°èªè­˜ã«ã¯ Development Build ãŒå¿…è¦ã§ã™ã€‚'
        }
        {'\n\n'}
        {speechSupported && 'â€» æ­£ç¢ºã§ãªã„ç™ºéŸ³ã‚‚å¿ å®Ÿã«å†ç¾ã•ã‚Œã¾ã™ã€‚'}
      </ThemedText>
    </ThemedView>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    padding: 20,
    alignItems: 'center',
    justifyContent: 'center',
  },
  title: {
    marginBottom: 40,
    textAlign: 'center',
  },
  recordingContainer: {
    alignItems: 'center',
    marginBottom: 40,
  },
  recordButton: {
    width: 120,
    height: 120,
    borderRadius: 60,
    alignItems: 'center',
    justifyContent: 'center',
    marginBottom: 10,
  },
  recordButtonText: {
    color: 'white',
    fontSize: 16,
    fontWeight: 'bold',
  },
  statusContainer: {
    alignItems: 'center',
    marginTop: 10,
  },
  timer: {
    fontSize: 16,
    marginTop: 10,
    color: '#333333',
    fontWeight: '500',
  },
  listeningStatus: {
    fontSize: 14,
    color: '#4CAF50',
    marginTop: 5,
    fontWeight: '500',
  },
  actionButtonsContainer: {
    flexDirection: 'row',
    gap: 10,
    marginBottom: 20,
  },
  playButton: {
    backgroundColor: '#2196F3',
    paddingHorizontal: 20,
    paddingVertical: 10,
    borderRadius: 8,
    flex: 1,
  },
  playButtonText: {
    color: 'white',
    fontSize: 16,
    fontWeight: 'bold',
    textAlign: 'center',
  },
  whisperButton: {
    backgroundColor: '#FF6B35',
    paddingHorizontal: 20,
    paddingVertical: 10,
    borderRadius: 8,
    flex: 1,
  },
  whisperButtonText: {
    color: 'white',
    fontSize: 16,
    fontWeight: 'bold',
    textAlign: 'center',
  },
  processingButton: {
    backgroundColor: '#999999',
  },
  supportInfo: {
    marginBottom: 20,
    alignItems: 'center',
  },
  supportText: {
    fontSize: 12,
    color: '#888888',
    marginBottom: 2,
  },
  helpButton: {
    backgroundColor: '#FF9800',
    paddingHorizontal: 12,
    paddingVertical: 6,
    borderRadius: 4,
    marginTop: 8,
  },
  helpButtonText: {
    color: 'white',
    fontSize: 12,
    fontWeight: 'bold',
  },
  instruction: {
    textAlign: 'center',
    fontSize: 14,
    color: '#666666',
    fontWeight: '400',
  },
  comparisonContainer: {
    width: '100%',
    marginBottom: 20,
    padding: 16,
    borderWidth: 2,
    borderColor: '#4CAF50',
    borderRadius: 12,
    backgroundColor: '#f0f8f0',
  },
  comparisonTitle: {
    fontSize: 18,
    fontWeight: 'bold',
    textAlign: 'center',
    marginBottom: 16,
    color: '#2E7D32',
  },
  comparisonRow: {
    flexDirection: 'row',
    justifyContent: 'space-between',
    marginBottom: 16,
    gap: 10,
  },
  comparisonItem: {
    flex: 1,
    padding: 12,
    borderRadius: 8,
    backgroundColor: '#ffffff',
    borderWidth: 1,
    borderColor: '#e0e0e0',
  },
  comparisonLabel: {
    fontSize: 12,
    color: '#666666',
    marginBottom: 6,
    fontWeight: '500',
  },
  comparisonText: {
    fontSize: 16,
    fontWeight: 'bold',
    color: '#000000',
    minHeight: 20,
  },
  whisperRawContainer: {
    padding: 12,
    borderRadius: 8,
    backgroundColor: '#fff3e0',
    borderWidth: 1,
    borderColor: '#ffb74d',
    marginBottom: 12,
  },
  whisperRawLabel: {
    fontSize: 12,
    color: '#e65100',
    marginBottom: 4,
    fontWeight: '500',
  },
  whisperRawText: {
    fontSize: 14,
    color: '#bf360c',
    fontFamily: 'monospace',
    fontStyle: 'italic',
  },
  clearComparisonButton: {
    backgroundColor: '#ff5722',
    paddingHorizontal: 16,
    paddingVertical: 8,
    borderRadius: 6,
    alignSelf: 'center',
  },
  clearComparisonButtonText: {
    color: 'white',
    fontSize: 12,
    fontWeight: 'bold',
  },
  resultItem: {
    marginBottom: 15,
  },
  resultLabel: {
    fontSize: 14,
    color: '#333333',
    fontWeight: '600',
    marginBottom: 5,
  },
  resultText: {
    fontSize: 18,
    color: '#000000',
    fontWeight: 'bold',
    backgroundColor: '#f0f0f0',
    padding: 10,
    borderRadius: 8,
  },
});